{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from hjorth import Hjorth\n",
    "from paths import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoother(fn, skip=5):\n",
    "    id = fn.split('.')[0]\n",
    "    eeg = pd.read_parquet(paths.TRAIN_EEGS + fn)\n",
    "    numrows = eeg.shape[0]\n",
    "    smoothed_eeg = pd.DataFrame()\n",
    "    for col in eeg.columns:\n",
    "        given = np.array(eeg[col])\n",
    "        array = [np.nanmean(given[i: i+skip]) for i in range(0, numrows, skip)]\n",
    "        smoothed_eeg[col] = np.nan_to_num(array)\n",
    "    np.save(f'cleaned_train_eegs_{skip}/{id}.npy', smoothed_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_smoother(skip):\n",
    "    for _, _, files in os.walk(\"./train_eegs\"):\n",
    "        Parallel(n_jobs=-1)(delayed(smoother)(fn, skip) for fn in tqdm(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_smoother(fn, skip=20):\n",
    "    id = fn.split('.')[0]\n",
    "    eeg = pd.DataFrame(np.load(paths.TRAIN_CLEAN_10 + id + '.npy'))\n",
    "    numrows = eeg.shape[0]\n",
    "    smoothed_eeg = pd.DataFrame()\n",
    "    for col in eeg.columns:\n",
    "        given = np.array(eeg[col])\n",
    "        smoothed_eeg[col] = [np.mean(given[i: i+2]) for i in range(0, numrows, 2)]\n",
    "    np.save(f'cleaned_train_eegs_{skip}/{id}.npy', smoothed_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_parallel_smoother(skip):\n",
    "    for _, _, files in os.walk('./train_eegs'):\n",
    "        Parallel(n_jobs=-1)(delayed(custom_smoother)(fn, skip) for fn in tqdm(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft\n",
    "\n",
    "def generalized(eeg):\n",
    "    left = None\n",
    "    right = None\n",
    "    for key in paths.LABEL_SIDES.keys():\n",
    "        key_array = np.array(eeg[key]).reshape(-1,)\n",
    "        P = np.abs(fft(key_array))\n",
    "        if paths.LABEL_SIDES[key] == 'left':\n",
    "            if left is None:\n",
    "                left = P\n",
    "            else: left += P\n",
    "        elif paths.LABEL_SIDES[key] == 'right':\n",
    "            if right is None:\n",
    "                right = P\n",
    "            else: right += P\n",
    "                \n",
    "    left = np.array(left[30:-15])\n",
    "    right = np.array(right[30:-15])\n",
    "\n",
    "    score = (np.mean(left - right))**2 / (np.mean(left + right))**2\n",
    "    return -np.log(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hjorth_data(id, sub_id, offset):\n",
    "    raw_eeg = pd.DataFrame(np.load(paths.TRAIN_CLEAN_10 + f'{int(id)}.npy'))\n",
    "    eeg = raw_eeg.loc[(offset + 20) * 20 : (offset + 30) * 20]\n",
    "    eeg.columns = paths.EEG_LABELS\n",
    "    size = 3 * len(eeg.columns) + 1\n",
    "    array = np.zeros(size)\n",
    "    for i, col in enumerate(eeg.columns):\n",
    "        signal = Hjorth(list(eeg[col]), 20)\n",
    "        a, m, c = signal.amc()\n",
    "        array[3 * i] = a\n",
    "        array[3 * i + 1] = m\n",
    "        array[3 * i + 2] = c\n",
    "    array[-1] = generalized(eeg)\n",
    "    np.save(f'hjorth_10/{int(id)}_{int(sub_id)}.npy', array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(paths.TRAIN_CSV)\n",
    "file_data = df[['eeg_id', 'eeg_sub_id', 'eeg_label_offset_seconds']]\n",
    "file_data.columns = ['id', 'sub_id', 'offset']\n",
    "\n",
    "Parallel(n_jobs=-1)(delayed(hjorth_data)(**file_data.loc[idx]) for idx in tqdm(file_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_freq: int = 20, sampling_rate: int = 200, order: int = 4):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "FEATURES = ['Fp1', 'T3', 'C3', 'O1', 'Fp2', 'C4', 'T4', 'O2']\n",
    "\n",
    "def traindata(fn):\n",
    "    id = fn.split('.')[0]\n",
    "    eeg = pd.read_parquet(paths.TRAIN_EEGS + fn, columns=FEATURES)\n",
    "    eeg = eeg.loc[:10000, :]\n",
    "    if eeg.isna().sum().sum() != 0:\n",
    "        for col in eeg.columns:\n",
    "            imputer = KNNImputer(n_neighbors=4)\n",
    "            eeg[col] = imputer.fit_transform(eeg.loc[:,[col]])\n",
    "    np_eeg = eeg.to_numpy()\n",
    "    np_eeg = butter_lowpass_filter(np_eeg)\n",
    "    np_eeg = np_eeg[::5,:]\n",
    "    np.save(f'clean_train/{id}.npy', np_eeg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_cleaner():\n",
    "    for _, _, files in os.walk(\"./train_eegs\"):\n",
    "        Parallel(n_jobs=-1)(delayed(traindata)(fn) for fn in tqdm(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import pywt\n",
    "\n",
    "def maddest(d, axis=None):\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "def denoise(x, wavelet='db8', level=1):\n",
    "    ret = np.zeros_like(x)\n",
    "\n",
    "    for i, pos in enumerate(x.columns):\n",
    "        coeff = pywt.wavedec(x[pos], wavelet, mode=\"per\")\n",
    "        sigma = (1/0.6745) * maddest(coeff[-level])\n",
    "\n",
    "        uthresh = sigma * np.sqrt(2*np.log(len(x)))\n",
    "        coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard')\n",
    "                     for i in coeff[1:])\n",
    "\n",
    "        ret[:,i] = pywt.waverec(coeff, wavelet, mode='per')\n",
    "\n",
    "    return ret\n",
    "\n",
    "FEATURES = ['Fp1', 'T3', 'C3', 'O1', 'Fp2', 'C4', 'T4', 'O2']\n",
    "\n",
    "def denoised_data(fn):\n",
    "    id = fn.split('.')[0]\n",
    "    eeg = pd.read_parquet(paths.TRAIN_EEGS + fn, columns=FEATURES)\n",
    "    eeg = eeg.loc[:9999, :]\n",
    "    if eeg.isna().sum().sum() != 0:\n",
    "        for col in eeg.columns:\n",
    "            imputer = KNNImputer(n_neighbors=4)\n",
    "            eeg[col] = imputer.fit_transform(eeg.loc[:, [col]])\n",
    "    np_eeg = denoise(eeg)\n",
    "    np_eeg = np_eeg[::5, :]\n",
    "    np.save(f'denoised_train/{id}.npy', np_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_denoiser():\n",
    "    for _, _, files in os.walk(\"./train_eegs\"):\n",
    "        Parallel(n_jobs=-1)(delayed(denoised_data)(fn) for fn in tqdm(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 612/17300 [00:09<02:52, 96.65it/s] \n",
      "100%|██████████| 17300/17300 [08:30<00:00, 33.86it/s] \n"
     ]
    }
   ],
   "source": [
    "parallel_denoiser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get main 8 features from 20 in EEG and take only first 2,000 recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fp1': 0, 'F3': 1, 'C3': 2, 'P3': 3, 'F7': 4, 'T3': 5, 'T5': 6, 'O1': 7, 'Fz': 8, 'Cz': 9, 'Pz': 10, 'Fp2': 11, 'F4': 12, 'C4': 13, 'P4': 14, 'F8': 15, 'T4': 16, 'T6': 17, 'O2': 18, 'EKG': 19}\n"
     ]
    }
   ],
   "source": [
    "FEATURES = ['Fp1', 'T3', 'C3', 'O1', 'Fp2', 'C4', 'T4', 'O2']\n",
    "FEATS2OLDIDX = {paths.EEG_LABELS[i] : i for i in range(20)}\n",
    "print(FEATS2OLDIDX)\n",
    "\n",
    "def extract_main(fn):\n",
    "    id = fn.split('.')[0]\n",
    "    eeg = np.load(paths.TRAIN_CLEAN_5 + fn)[:2000]\n",
    "    new_eeg = np.zeros((2000, 8))\n",
    "    for i, feat in enumerate(FEATURES):\n",
    "        new_eeg[:,i] = eeg[:,FEATS2OLDIDX[feat]]\n",
    "    np.save(f'train_sk5_8/{id}.npy', new_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_extract_main():\n",
    "    for _, _, files in os.walk(\"./cleaned_train_eegs_5\"):\n",
    "        Parallel(n_jobs=-1)(delayed(extract_main)(fn) for fn in tqdm(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17300/17300 [00:28<00:00, 615.12it/s]\n"
     ]
    }
   ],
   "source": [
    "parallel_extract_main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
